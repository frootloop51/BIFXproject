{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98768b41",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb64152a",
   "metadata": {},
   "source": [
    "#### Question 1a:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96324421",
   "metadata": {},
   "source": [
    "There are many kinds of maching learning that could be used to classify the yeast types in question. These include kNN/Nearest neighbors, Naive Bayes, or the C5.0 algorithm.\n",
    "\n",
    "##### KNN\n",
    "KNN is an algorithm that \"uses information about an example's k nearest neighbors to classify unlabeled examples\" (Lecture 2). The \"k\" in the algorithms name is a variable that defines the number of nearest neighbors used to classify the unlabeled example.\n",
    "- Advantages (Lecture 2)\n",
    "    - This is a \"lazy learner\" algorithm and does not abstract the data. This allows it to classify data quickly.\n",
    "    - KNN is easy to implement and all that is needed is for the user to set the k (number of neareset neighbors).\n",
    "- Disadvantages (references from: https://theprofessionalspoint.blogspot.com/2019/02/advantages-and-disadvantages-of-knn.html)\n",
    "    - It does not work well on large datasets.\n",
    "    - Data with many dimensions becomes hard to measure because measuring the distance in each dimension is difficult.\n",
    "    - Requires data to be normalized. If this is not done, the algorithm may make very inaccurate predictions.\n",
    "    - KNN is sensitive to overfitting and underfitting data (bias-variance tradeoff). By choosing to high or low of a k-value the algorithm could become unreliable in predicting data.\n",
    "\n",
    "##### Naive Bayes\n",
    "Probability based methods like the Naive Bayes Algorithm \"...utilize training data to calculate the probability of each outcome based on the evidence provided by feature values. When the classifier is later applied to unlabeled data, it uses these calculated probabilities to predict the most likely class for the new example\" (Lecture 3).\n",
    "- Advantages (all references from Lecture 3)\n",
    "    - The algorithm is versatile and accurate across many types of conditions.\n",
    "    - Also good with smaller datasets.\n",
    "- Disadvantages (all references from Lecture 3)\n",
    "    -  The algorithm \"assumes that all of the features in the dataset are equally important and independent. These assumptions are rarely true in most real-world applications.\".\n",
    " \n",
    "##### C5.0 Decision Tree Algorithm\n",
    "Decision Tree models like C5.0 \"...split the data into subsets, which are then split repeatedly into even smaller subsets, until the process stops when the algorithm determines the data within the subsets are sufficiently homogenous, or another stopping criterion has been met (Lecture 4).\n",
    "\n",
    "- Advantages (all references from Lecture 4)\n",
    "    - All purpose classifer that works well on many types of problems.\n",
    "    - Excludes unimportant features.\n",
    "    - Good on both small and large datasets.\n",
    "    - Does not require mathemetical background to understand results.\n",
    "- Disadvantages (all references from Lecture 4)\n",
    "    -  Can be biased toward splits on variables with many levels.\n",
    "    - Can easily overfit or underfit the model.\n",
    "    - Small changes in training data can result in big changes in decision logic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eea47c4",
   "metadata": {},
   "source": [
    "#### Question 1b: Parameters and Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e7c50",
   "metadata": {},
   "source": [
    "When using these models, different parameters and architecture/design must be taken into account to ensure your results are reliable as possible.\n",
    "\n",
    "##### KNN\n",
    "Looking at the data, it looks like it may be a good candidate for KNN because I'm assuming it is looking at physical measurements of the yeast types. KNN tends to perform fairly well on measure of physiacl data. Each type of yeast has 8 numeric attributes. Because KNN is not great with categorical variables and it would make normalizing the data difficult, I would recommend changing yeast types from categorical (TypeA, TypeB, etc.) to integers 1 through 10.\n",
    "\n",
    "After changing the categorical data to integer data, I would use min-max normalization on the entire dataset.\n",
    "\n",
    "The next step would involved randomly dividing the data into test and training data.  Because the data has many classes and dividing it randomly could lead to imbalances in the testing and training sets, I'd use the createDataPartition() function which \"...splits data into training and testing partitions while keeping the relative sample size of the classes the same as in the original data\" (https://search.r-project.org/CRAN/refmans/deforestable/html/createDataPartition.html). Using this function, I'd recommend a 70/30 ratio for the testing to training sets. This can be defined in the function.\n",
    "\n",
    "Now that the data is split into testing and training data, I'd use the knn() function and set the k at 39 (I rounded up from the square root of 1,486).\n",
    "\n",
    "To evaluate the results I'd use the Crosstable function and compare the predicted to actual results and look at the per class precision, recall, and f-1 scores. There should be 10.\n",
    "\n",
    "##### Naive Bayes\n",
    "The process for setting up this algorithm is similar except for the fact that we do not need to change the yeast type data to integers and can leave them as categorical variables. Additonally, we do not need to normalize the data.\n",
    "\n",
    "Moving right along, we can simply use the createDataPartition() function and split the data 70/30 into testing and training data.\n",
    "\n",
    "Because there are no zero probability events in this data, we do not need to worry about the Laplace estimator.\n",
    "\n",
    "Finally, we can use the the Crosstable function to compare the predicted to actual results and look at the per class precision, recall, and f-1 scores. There should be 10.\n",
    "\n",
    " \n",
    "##### C5.0 Decision Tree Algorithm\n",
    "Similar to the above, the data seems well prepared for analysis, so we can use the createDataPartition() function and split the data 70/30 into testing and training data.\n",
    "\n",
    "Then, we can use the the Crosstable function to compare the predicted to actual results and look at the per class precision, recall, and f-1 scores. There should be 10.\n",
    "\n",
    "Based on the results of the crosstable, we can then do some boosting by specifying the algorithm to run more trials or assign a cost matrix to encourage different predictions based on the goal of the analysis.\n",
    "\n",
    "We can also use the caret package to perform automated tuning  \"to search a set of candidate models comprising a matrix, or grid, of parameter combinations. Because it is impractical to search every conceivable combination, only a subset of possibilities is used to construct the grid. By default, caret searches at most three values for each of the model's  ùëù  parameters, which means that at most  3ùëù candidate models will be tested\" (Lecture 8).\n",
    "\n",
    "Using this information we can then optimize model perormance by customizing the tuning process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e4bda",
   "metadata": {},
   "source": [
    "#### Question 1c: Procedure for Training and Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d93f45f",
   "metadata": {},
   "source": [
    "The dataset is very imbalanced. In fact, Yeast Types A, B, and C make up more than 75% of the dataset. Becuase they are so over represented, this will bias any machine learning algorithm to predict these three classes very well at the cost of the other samples. \n",
    "\n",
    "Because this is a classification problem, it is probably safest to use the createDataPartition() function to maintain the same distirbutions in the testing and training data (https://www.kaggle.com/general/238949). This process is described above.\n",
    "\n",
    "But we could also oversample or undersample. \"Random oversampling involves randomly selecting examples from the minority class, with replacement, and adding them to the training dataset. Random undersampling involves randomly selecting examples from the majority class and deleting them from the training dataset\" (https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/).This can be done using the caret package to perform automated tuning  \"to search a set of candidate models comprising a matrix, or grid, of parameter combinations\" (Lecture 8).\n",
    "\n",
    "First we would model the original unbalanced data stratfied by class (createDataPartition) and perform a random forset modeling with repeated cross validation. Then, we would use the trainControl() function and add a sampling parameter and choose \"down\" to undersample. This process would be very similar for oversampling where we would specify \"up\" for the sampling parameter (https://www.r-bloggers.com/2017/04/dealing-with-unbalanced-data-in-machine-learning/).\n",
    "\n",
    "We could also use ROSE or SMOTE methods, hybrid methods that both undersample and oversample at the same time. These can be selected in the same way as oversampling and undersampling, all you have to do is specify \"smote\" or \"rose\" in the sampling parameter. Because there are so many data classes, I would probably choose smote, as rose is meant for binary classification (https://www.r-bloggers.com/2017/04/dealing-with-unbalanced-data-in-machine-learning/).\n",
    "\n",
    "It's difficult to speculate on the best method for this data, but I assume a hybrid method will be necessary because the data classes are extremely imbalanced.\n",
    "\n",
    "For coding examples of these types of over/under sampling, please follow this link: https://www.r-bloggers.com/2017/04/dealing-with-unbalanced-data-in-machine-learning/. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d8509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
